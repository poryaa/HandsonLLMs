{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e2849cf",
   "metadata": {},
   "source": [
    "# Chapter04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cdb431",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer,T5ForConditionalGeneration\n",
    "\n",
    "model_name = \"t5-small\"\n",
    "model =T5ForConditionalGeneration.from_pretrained(model_name)\n",
    "tokenizer = T5Tokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0856ed5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "pipe = pipeline(\n",
    "    task=\"text2text-generation\",\n",
    "    model=model,\n",
    "    tokenizer=tokenizer,\n",
    "    device=\"cuda:0\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e172a4d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "data = load_dataset(\"rotten_tomatoes\")\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1623a973",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"Is the following sentence positive or negative?\"\n",
    "data = data.map(lambda example: {\"t5\": prompt + example[\"text\"]})\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c994e61",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "def evaluate_performance(y_true, y_pred):\n",
    "    \"\"\"Create and print the classification report\"\"\"\n",
    "    performance = classification_report(\n",
    "        y_true, y_pred,\n",
    "        target_names=[\"Negative Review\", \"Positive Review\"]\n",
    "    )\n",
    "    print(performance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30a24ca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from transformers.pipelines.pt_utils import KeyDataset\n",
    "\n",
    "\n",
    "y_pred = []\n",
    "for output in tqdm(pipe(KeyDataset(data[\"test\"], \"t5\")), total=len(data[\"test\"])):\n",
    "    text = output[0][\"generated_text\"]\n",
    "    y_pred.append(0 if text == \"negative\" else 1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d1c386",
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_performance(data[\"test\"][\"label\"], y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce7b478",
   "metadata": {},
   "source": [
    "# Chapter 05"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883593d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "dataset = load_dataset(\"maartengr/arxiv_nlp\")[\"train\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f6a01e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b61ffce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "abstracts = dataset[\"Abstracts\"]\n",
    "titles = dataset[\"Titles\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6aa183fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "embedding_model = SentenceTransformer(\"thenlper/gte-small\")\n",
    "embeddings = embedding_model.encode(abstracts, show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3152932",
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c9b8a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from umap import UMAP\n",
    "\n",
    "umap_model = UMAP(n_components= 5, min_dist=0.0, metric=\"cosine\", random_state=42)\n",
    "reduced_embeddings =umap_model.fit_transform(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "336c7943",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hdbscan import HDBSCAN\n",
    "hdbscan_model = HDBSCAN(min_cluster_size=50, metric=\"euclidean\", cluster_selection_method=\"eom\").fit(reduced_embeddings)\n",
    "clusters =hdbscan_model.labels_\n",
    "len(set(clusters))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56faf155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Reduce 384-dimensional embeddings to 2 dimensions for easier visualization\n",
    "reduced_embeddings = UMAP(\n",
    "    n_components=2, min_dist=0.0, metric='cosine', random_state=42\n",
    ").fit_transform(embeddings)\n",
    "\n",
    "# Create dataframe\n",
    "df = pd.DataFrame(reduced_embeddings, columns=[\"x\", \"y\"])\n",
    "df[\"title\"] = titles\n",
    "df[\"cluster\"] = [str(c) for c in clusters]\n",
    "\n",
    "# Select outliers and non-outliers (clusters)\n",
    "clusters_df = df.loc[df.cluster != \"-1\", :]\n",
    "outliers_df = df.loc[df.cluster == \"-1\", :]\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot outliers and non-outliers seperately\n",
    "plt.scatter(outliers_df.x, outliers_df.y, alpha=0.05, s=2, c=\"grey\")\n",
    "plt.scatter(\n",
    "    clusters_df.x, clusters_df.y, c=clusters_df.cluster.astype(int),\n",
    "    alpha=0.6, s=2, cmap='tab20b'\n",
    ")\n",
    "plt.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f9431fa",
   "metadata": {},
   "source": [
    "# Chapter 06"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b9aa112",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`flash-attention` package not found, consider installing for better performance: No module named 'flash_attn'.\n",
      "Current `flash-attention` does not support `window_size`. Either upgrade or use `attn_implementation='eager'`.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1862d63ca1b946dba9eac28ce0cb6bfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline, AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_name = \"microsoft/Phi-3-mini-4k-instruct\"\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(model_name,\n",
    "                                             device_map=\"cuda\",\n",
    "                                             torch_dtype=\"auto\",\n",
    "                                             trust_remote_code=True)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "pipe = pipeline(task=\"text-generation\",\n",
    "                model=model,\n",
    "                tokenizer=tokenizer,\n",
    "                return_full_text=False,\n",
    "                max_new_tokens=500,\n",
    "                do_sample=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f6a700a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Why did the chicken join the band? Because it had the drumsticks!'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#prompt\n",
    "messages = [{\"role\": \"user\",\n",
    "             \"content\": \"Create a funny joke about chickens.\"}]\n",
    "#generate the output\n",
    "output = pipe(messages)\n",
    "output[0][\"generated_text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "4eb7bef2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|user|>\n",
      "Create a funny joke about chickens.<|end|>\n",
      "<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "prompt = pipe.tokenizer.apply_chat_template(messages, tokenize=False)\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec5df25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' Why did the chicken join the band? Because it had the drumsticks!'}]\n"
     ]
    }
   ],
   "source": [
    "output = pipe(messages, do_sample=True, temperature=1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "49ae8bde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'generated_text': ' Why did the chicken join a band? Because it had the perfect eggsonic.'}]\n"
     ]
    }
   ],
   "source": [
    "output = pipe(messages, do_sample=True, top_p=1)\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "b9b9e7f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Name: ChatSage\n",
      "Slogan: \"Your AI Companion for Smart Conversations\"\n"
     ]
    }
   ],
   "source": [
    "product_prompt =[{\"role\":\"user\",\n",
    "                  \"content\": \" Create a name and slogan for a chatbot that leverages LLMs.\"}]\n",
    "outputs = pipe(product_prompt)\n",
    "product_description = outputs[0][\"generated_text\"]\n",
    "print(product_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "8c61e2c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Introducing ChatSage, your AI Companion for Smart Conversations! With ChatSage, you'll have a personalized and intelligent assistant at your fingertips, ready to engage in meaningful dialogue, provide helpful information, and make your interactions more enjoyable and efficient. Say goodbye to awkward silences and hello to a world of smart conversations with ChatSage by your side.\n"
     ]
    }
   ],
   "source": [
    "sales_prompt=[{\"role\":\"user\",\n",
    "               \"content\": f\"Generate a very short sales pitch for the following product: '{product_description}'\"}]\n",
    "outputs = pipe(sales_prompt)\n",
    "sales_pitch = outputs[0][\"generated_text\"]\n",
    "print(sales_pitch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3b34046",
   "metadata": {},
   "source": [
    "# Chapter 07"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca3203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2025-09-24 20:26:42--  https://huggingface.co/microsoft/Phi-3-mini-4k-instruct-gguf/resolve/main/Phi-3-mini-4k-instruct-fp16.gguf\n",
      "Resolving huggingface.co (huggingface.co)... 2600:9000:243d:2a00:17:b174:6d00:93a1, 2600:9000:243d:ae00:17:b174:6d00:93a1, 2600:9000:243d:b200:17:b174:6d00:93a1, ...\n",
      "Connecting to huggingface.co (huggingface.co)|2600:9000:243d:2a00:17:b174:6d00:93a1|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://cas-bridge.xethub.hf.co/xet-bridge-us/662698108f7573e6a6478546/a9cdcf6e9514941ea9e596583b3d3c44dd99359fb7dd57f322bb84a0adc12ad4?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250924%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250924T182644Z&X-Amz-Expires=3600&X-Amz-Signature=4e47a8c1680415e6cc8974fe7df74e3eb48feee31747e8d03c9efc9d847b0fcb&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-fp16.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-fp16.gguf%22%3B&x-id=GetObject&Expires=1758742004&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1ODc0MjAwNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NjI2OTgxMDhmNzU3M2U2YTY0Nzg1NDYvYTljZGNmNmU5NTE0OTQxZWE5ZTU5NjU4M2IzZDNjNDRkZDk5MzU5ZmI3ZGQ1N2YzMjJiYjg0YTBhZGMxMmFkNCoifV19&Signature=AXsgAofEswIJouCjET3eOQLkZnHACS4-%7EqA8vN1kSMSQWwCj3NqRuDlPXNDLQ-rfDZ77FE93D5rZl8-muJU4dd9jApHsmQWfw5qllpgkXZ-brVoH5XERqk5QEmljspXuJZvmYz3ha2PitL9%7Ezvp4BfKwwyBJyS5Qbb0eb53d3mrew5ebSWInwQ%7E-G4h8Y8z5eI7nVRJu6PNwlrDHazB9uZO23R4Zs0avPzW3I5G1-8zlq7dVY3S1BXX-Anf0OVRlrfsQA00Mv1cRq3kqdNl3GuIrJj6%7E9e3nwARQB95V8DfGNDOhI0kp9HljRQIP0EjesUoSzThxN1V6hvx8P0Zr6Q__&Key-Pair-Id=K2L8F4GPSG1IFC [following]\n",
      "--2025-09-24 20:26:44--  https://cas-bridge.xethub.hf.co/xet-bridge-us/662698108f7573e6a6478546/a9cdcf6e9514941ea9e596583b3d3c44dd99359fb7dd57f322bb84a0adc12ad4?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Content-Sha256=UNSIGNED-PAYLOAD&X-Amz-Credential=cas%2F20250924%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20250924T182644Z&X-Amz-Expires=3600&X-Amz-Signature=4e47a8c1680415e6cc8974fe7df74e3eb48feee31747e8d03c9efc9d847b0fcb&X-Amz-SignedHeaders=host&X-Xet-Cas-Uid=public&response-content-disposition=inline%3B+filename*%3DUTF-8%27%27Phi-3-mini-4k-instruct-fp16.gguf%3B+filename%3D%22Phi-3-mini-4k-instruct-fp16.gguf%22%3B&x-id=GetObject&Expires=1758742004&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc1ODc0MjAwNH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2FzLWJyaWRnZS54ZXRodWIuaGYuY28veGV0LWJyaWRnZS11cy82NjI2OTgxMDhmNzU3M2U2YTY0Nzg1NDYvYTljZGNmNmU5NTE0OTQxZWE5ZTU5NjU4M2IzZDNjNDRkZDk5MzU5ZmI3ZGQ1N2YzMjJiYjg0YTBhZGMxMmFkNCoifV19&Signature=AXsgAofEswIJouCjET3eOQLkZnHACS4-%7EqA8vN1kSMSQWwCj3NqRuDlPXNDLQ-rfDZ77FE93D5rZl8-muJU4dd9jApHsmQWfw5qllpgkXZ-brVoH5XERqk5QEmljspXuJZvmYz3ha2PitL9%7Ezvp4BfKwwyBJyS5Qbb0eb53d3mrew5ebSWInwQ%7E-G4h8Y8z5eI7nVRJu6PNwlrDHazB9uZO23R4Zs0avPzW3I5G1-8zlq7dVY3S1BXX-Anf0OVRlrfsQA00Mv1cRq3kqdNl3GuIrJj6%7E9e3nwARQB95V8DfGNDOhI0kp9HljRQIP0EjesUoSzThxN1V6hvx8P0Zr6Q__&Key-Pair-Id=K2L8F4GPSG1IFC\n",
      "Resolving cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)... 54.192.97.113, 54.192.97.120, 54.192.97.46, ...\n",
      "Connecting to cas-bridge.xethub.hf.co (cas-bridge.xethub.hf.co)|54.192.97.113|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 7643295904 (7.1G)\n",
      "Saving to: ‘Phi-3-mini-4k-instruct-fp16.gguf’\n",
      "\n",
      "Phi-3-mini-4k-instr   0%[                    ]   4.32M   641KB/s    eta 3h 13m ^C\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "22ae385d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_ollama.llms import OllamaLLM\n",
    "\n",
    "llm_model = OllamaLLM(model=\"llama3.1\",\n",
    "                  n_gpu_layers=-1,\n",
    "                  max_tokens=500,\n",
    "                  n_ctx=2048,\n",
    "                  seed=42,\n",
    "                  verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "20399212",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Nice to meet you, Marten! How's your day going so far? Is there something I can help you with or would you like to chat about something in particular?\""
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model.invoke(\"Hi! My name is Marten\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ff638b59",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The answer to 1 + 1 is... 2!'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import PromptTemplate\n",
    "template = \"\"\"{input_prompt}\"\"\"\n",
    "\n",
    "prompt = PromptTemplate(template=template,\n",
    "                        input_variable=[\"input_prompt\"])\n",
    "\n",
    "basic_chain = prompt | llm_model\n",
    "basic_chain.invoke({\"input_prompt\":\" Hi! what is 1+1?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "386a8044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'a girl that lost her mother',\n",
       " 'title': '\"A Mother\\'s Absence, A Heart\\'s Lament\"',\n",
       " 'charchter': \"The main character, Sophia, is a 12-year-old girl who has been struggling to cope with the sudden loss of her mother, still reeling from the overwhelming grief and sense of abandonment that has left her feeling lost and alone in the world. With a heart full of tears and questions, Sophia embarks on a journey of self-discovery, seeking answers about her mother's passing while trying to find a way to heal and move forward without the one person she loved most.\",\n",
       " 'story': \"A Mother's Absence, A Heart's Lament: Sophia sat amidst the silence of her empty home, the echoes of memories now tinged with an aching sorrow. It had been six months since her mother's sudden passing, but the pain still felt like a fresh wound that refused to heal. With tears streaming down her face, Sophia wandered through the familiar rooms, searching for answers to questions she couldn't quite articulate. Why did Mom leave me? Was it something I did wrong? The what-ifs swirled in her head like a maelstrom, threatening to consume her whole. Yet, as she gazed out at the fading light of day, Sophia felt an insistent whisper within: it's time to rise, little one – time to find your own voice, your own strength, and learn to navigate this treacherous world without the guiding love of your mother by your side.\"}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain import LLMChain\n",
    "\n",
    "template =\"\"\"Create a title for a story about {summary}.Only return the title\"\"\"\n",
    "title_prompt = PromptTemplate(template= template, input_variables=[\"summary\"])\n",
    "title = LLMChain(llm=llm_model,prompt=title_prompt, output_key=\"title\")\n",
    "title.invoke({\"summary\": \"A girl that lost her mother.\"})\n",
    "\n",
    "template =\"\"\"Describe the main character of a story about {summary}.\n",
    "with the title of {title}. use only 2 sentences.\"\"\"\n",
    "charchter_prompt = PromptTemplate(template= template, input_variables=[\"summary\",\"title\"])\n",
    "charchter = LLMChain(llm=llm_model, prompt=charchter_prompt, output_key=\"charchter\")\n",
    "\n",
    "template =\"\"\"Create a story about {summary}. the main charachter is {title}.\n",
    "# with the title of {charchter}. Only return the story and it can not be longer than one paragraph.\"\"\"\n",
    "story_prompt = PromptTemplate(template= template, input_variables=[\"summary\",\"title\",\"charchter\"])\n",
    "story = LLMChain(llm=llm_model, prompt=story_prompt, output_key=\"story\")\n",
    "\n",
    "llm_chain = title | charchter | story\n",
    "llm_chain.invoke(\"a girl that lost her mother\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db4b555",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "LangChain",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
